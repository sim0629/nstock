#!/usr/bin/env python3

from keras.layers.core import Dense, Dropout, Activation
from keras.models import Sequential
from keras.utils.np_utils import to_categorical
from konlpy.tag import Hannanum
from konlpy.tag import Kkma
from konlpy.tag import Komoran
from konlpy.tag import Mecab
from pymongo import MongoClient
import datetime
import math
import numpy as np
import sys

nlp = Mecab()

client = MongoClient()
db = client['nstock']
news = db['news']
price = db['price']

def get_nts(code, n):
    nts = {}
    for doc in news.find({ 'code': code }).sort('dt', 1).limit(n):
        for noun in set(nlp.nouns(doc['body'])):
            if noun in nts:
                nts[noun] += 1
            else:
                nts[noun] = 1
    return nts

def get_idf(nts, n):
    idf = {}
    for ntk in nts:
        idf[ntk] = math.log10(n / nts[ntk])
    return idf

def get_tf_idf(code, idf, n, train):
    if train:
        col = news.find({ 'code': code }).sort('dt', 1).limit(n)
    else:
        col = news.find({ 'code': code }).sort('dt', 1).skip(n)
    for doc in col:
        # price
        dt = doc['dt']
        dtmin = dt.replace(minute=dt.minute//10*10, second=0, microsecond=0)
        dtmax = dtmin + datetime.timedelta(minutes=20)
        le = price.find_one({ 'code': code, 'dt': dtmin })
        re = price.find_one({ 'code': code, 'dt': dtmax })
        if le is None or re is None:
            continue
        if re['price'] >= le['price']:
            label = 1
        else:
            label = 0
        # news
        tf = {}
        for noun in idf:
            tf[noun] = 0
        for noun in nlp.nouns(doc['body']):
            if noun in tf:
                tf[noun] += 1
        max_tf = max(tf.values())
        tfidf = []
        for k in tf:
            a = tf[k] / (max_tf + 1)
            tfidf.append(a * idf[k])
        yield (tfidf, label)

def confusion_matrix(n, expected, predicted):
    mat = np.zeros((n, n), dtype=np.int)
    for i in range(len(expected)):
        mat[expected[i]][predicted[i]] += 1
    return mat

def run(code):
    print('===================================')
    n = int(news.find({ 'code': code }).count() * 0.8)
    print('code = %s, n = %d' % (code, n))

    print('getting training data...')
    nts = get_nts(code, n)
    idf = get_idf(nts, n)
    X = []
    Y = []
    for (x, y) in get_tf_idf(code, idf, n, True):
        X.append(x)
        Y.append(y)
    X_train = np.asarray(X)
    Y_train = np.asarray(Y)

    dim = len(X[0])
    print('dim = %d' % dim)

    print('preparing model...')
    model = Sequential()
    model.add(Dense(output_dim=4096, input_dim=dim, init='uniform', activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(2048, init='uniform', activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1, init='uniform', activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

    print('fitting model...')
    model.fit(X_train, Y_train, nb_epoch=30, verbose=2)

    print('getting testing data...')
    X = []
    Y = []
    for (x, y) in get_tf_idf(code, idf, n, False):
        X.append(x)
        Y.append(y)
    X_test = np.asarray(X)

    print('predicting...')
    classes = model.predict_classes(X_test, verbose=2)

    print('confusion matrix')
    print(confusion_matrix(2, Y, classes))

if __name__ == '__main__':
    codes = [
        "084990", # 바이로메드
        "214370", # 케어젠
        "102940", # 코오롱생명과학
        "095700", # 제넥신
        "034830", # 한국토지신탁
        "046890", # 서울반도체
    ]
    for code in codes:
        run(code)
