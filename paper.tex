\documentclass[a4paper,10pt]{article}

\usepackage{kotex}
\usepackage{datetime}
\usepackage{fullpage}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}
\usepackage{multirow}
\usepackage{hyperref}

\newdateformat{koreandate}{\THEYEAR년 \twodigit{\THEMONTH}월 \twodigit{\THEDAY}일}
\renewcommand{\abstractname}{초록}
\renewcommand{\contentsname}{목차}
\renewcommand{\figurename}{그림}
\renewcommand{\tablename}{표}
\graphicspath{ {images/} }

\linespread{1.5}

\begin{document}

\title{뉴스 기사를 이용한 주식 가격의 변동 예측}
\author{
  서울대학교 컴퓨터공학부 \\
  2009-11744 심규민
}
\date{\koreandate\today}
\maketitle

\begin{abstract}
TODO
\end{abstract}

\tableofcontents

\thispagestyle{empty}
\pagebreak
\setcounter{page}{1}

\section{서론}

\subsection{연구 목적}

본 연구에서는 우리나라 주식 시장에 상장한 회사들에 관한 인터넷 뉴스 기사를 통해 그 회사들의 주가가 단기적으로 어떻게 변동할지 예측해보았다.
효율적 시장 가설(Efficient Market Hypothesis)에 따르면 주식 시장에는 수많은 요인이 반영되어 있기 때문에, 주가는 예측할 수 없게 움직인다.
주식 분석 방법 중 기본적 분석(Fundamental Analysis) 방법에 의하면 주가가 변동하는 요인은 회사의 실적, 전망 등 다양하다.
이러한 요인들에 대한 소식은 입소문, 뉴스를 통해 전달되지만, ``소문에 사고 뉴스에 팔아라''는 말이 있는 것처럼 뉴스는 주가보다 늦게 반응한다는 것이 중론이다.
그런데 Gidofalvi et al.의 연구에서 뉴스 기사로부터, 그 예측력은 낮지만 효율적 시장 가설에 반하는, 주가 변동의 예측이 가능함을 보여주었다.
본 연구는 이 선행 연구를 검증하는 목적으로 NASDAQ 시장이 아닌 국내 시장에 적용하여 보고자 하였다.
또한 선행 연구에서는 주가의 움직임을 예측할 때 나이브 베이즈 분류기(Naive Bayes Classifier)를 사용하였는데,
본 연구에서는 이것을, 최근 기계학습(Machine Learning) 분야에서 주목받고 있는, 인공신경망(Artificial Neural Network)으로 대체해보았다.

\subsection{선행 연구 분석}

선행 연구(Gidofalvi et al. 2001)는 다음과 같이 크게 네가지 단계로 이루어졌다.
\begin{enumerate}
\item 주가 데이터와 뉴스 기사 데이터의 수집
\item 주가에 따른 뉴스 기사의 정렬(alignment), 점수화(scoring), 레이블링(labelling)
\item 나이브 베이즈 분류기 학습(training)
\item 분류기 평가(evaluation)
\end{enumerate}
먼저, 특정 종목(회사)에 대해 시간별 주가 데이터와 뉴스 기사를 기사가 공개된 시각과 함께 수집한다.
그리고 나서 그 종목 뉴스 각각에 대해 정렬, 점수화, 레이블링 과정을 거친다.
정렬 과정에서는 임의의 시간 간격을 정해서 해당 뉴스가 공개된 시각을 기준으로 그 전 몇 분과 그 후 몇 분을 그 뉴스가 영향을 주는 범위로 보는 것이다.
예를 들어 $[-20, 30]$ 시간 간격에 대해, 어떤 뉴스가 오전 10시 30분에 공개 되었다면, 이 뉴스가 주가에 영향을 주는 범위는 오전 10시 10분부터 11시 0분까지가 된다.
정렬 과정에서는 이 범위가 주식 시장이 열려 있는 동안만으로 한정하여 그 밖에 위치한 뉴스들을 걸러내는 작업도 한다.
점수화 과정은 뉴스가 영향을 주는 범위의 시작 시각과 끝나는 시각의 주가의 상대적 변화를 수치화 하는 과정이다.
구체적으로는 끝나는 주가를 시작 주가로 나누어 로그를 취한 값($\Delta price$)을 정규화 하여 사용한다.
정규화는 각 종목에 대한 $\Delta price$를 그 종목의 변동성($\beta$-값)으로 나누고, 주식 시장 index에 대한 $\Delta price$를 빼는 작업이다.
레이블링 과정은 점수화의 결과가 특정 threshold $\rho_{positive}$, $\rho_{negative}$에 대해
$\rho_{positive}$ 보다 크면 해당 뉴스에 의해 주가가 올랐다($UP$)고 레이블링하고,
$\rho_{negative}$ 보다 작으면 내렸다($DOWN$)고 레이블링하며,
그 사이일 경우 변하지 않았다($EXP$)고 레이블링하는 작업이다.
뉴스 기사의 레이블링 작업이 끝나면, 뉴스의 내용을 이루고 있는 각 단어들에 대한 나이브 베이즈를 가정하고 분류기를 학습 시킨다.
분류기의 입력은 뉴스 기사의 내용이며 출력은 분류 레이블 ($UP, DOWN, EXP$) 중 하나이다.
마지막으로 이렇게 학습된 분류기를 이용하여, 최고의 성능을 갖는 정렬 시간 간격과 분류 threshold를 찾는다.

선행 연구의 결과는 논문 상에 정확한 정확도를 명시하지는 않았지만,
분류 threshold $\rho_{positive}=0.002$, $\rho_{negative}=-0.002$일 때 무작위 예측 보다 높은 성능을 보였고,
선행 연구 논문에서 제시한 그래프를 볼 때 그때의 $accuracy$는 약 $40\%$였다.
정렬 시간 간격은 $[-20,0]$과 $[0,20]$일 때 가장 의미 있는 성능을 내었으며,
$precision$과 $recall$은 각 레이블별로 다르지만 $30\%$에서 $50\%$ 사이였다.

\section{데이터 수집}

본 연구를 위해, 선행 연구와 마찬가지로, 주가 데이터와 뉴스 기사 데이터를 수집하였다.
데이터를 가져올 종목은 KOSDAQ 시장에서 시가 총액 상위 30개 종목 중 외국인 보유주 비율이 낮은(5\% 내외) 6개 종목으로 정했다.
그 이유는 첫째로 시가 총액이 큰 회사가 상대적으로 투자자들의 관심을 많이 받고 관련 뉴스가 많아서 인공 신경망을 학습 시킬 데이터를 많이 얻을 수 있다는 점이고,
둘째로는 KOSPI에 비해 주가가 낮은 KOSDAQ 종목 그리고 외국인 비율이 낮은 종목이 개인 투자자들의 거래 비율이 많을 것으로 예상되기 때문이다.
기관이나 외국인 등 투자 전문가들은 개인 투자자들에 비해 소식을 먼저 접하고 미리 움직일 가능성이 크다는 가정을 하였다.
선정된 종목은 바이로메드(084990), 케어젠(214370), 코오롱생명과학(102940), 제넥신(095700), 한국토지신탁(034830), 서울반도체(046890)이다.

\subsection{주가 데이터}

주가 데이터는 각 종목별로 날짜와 시각에 따른 주가의 리스트로 정의된다.
주가 데이터를 얻기 위해 국내의 한 증권사인 이베스트투자증권에서 제공하는 Xing API를 이용하였다.
Xing API의 COM(Component Object Model)을 사용하는 Windows Form 응용 프로그램을 C\# 언어로 구현하였다.
주가 데이터를 얻는 응용 프로그램의 전체적인 구조는 그림 \ref{fig:getting_price}와/과 같다.
\begin{figure}[h]
\includegraphics[width=0.9\textwidth]{getting_price}
\centering
\caption{주가 데이터 수집 응용 프로그램의 구조}
\label{fig:getting_price}
\end{figure}
먼저 증권사의 API를 사용하기 위해 계정 아이디와 비밀번호, 공인인증서 비밀번호 등 사용자 정보를 받는다.
받은 사용자 정보를 Session 객체에 넘겨 COM 인터페이스를 통해 로그인 한다.
로그인이 완료되면 사용자가 주가를 조회하고 싶은 종목 코드를 입력한다.
마지막으로 주가를 조회하는 Query를 요청하여 주가 데이터를 얻고 이를 파일로 출력한다.
이렇게 수집한 주가 데이터는 뉴스 기사 데이터와 함께 인공 신경망을 구축하기 위해 사용되었다.
이를 위해서 주가 데이터 파일을 읽어서 단순히 데이터베이스에 옮겨 저장하는 스크립트를 작성하였다.
이 스크립트는 Python 언어로 작성하였으며 DBMS는 MongoDB를 사용하였다.
실제로 앞서 선택한 6개의 종목에 대해 Xing API로 한번에 가져올 수 있는 최대치인 약 1년치(2015년 6월 2일부터 2016년 5월 24일까지)의 10분 간격 주가 데이터를 얻었다.
주가 데이터는 종목을 통틀어 약 5만 건이었다.

\subsection{뉴스 기사 데이터}

뉴스 기사 데이터는 각 종목별로 날짜와 시각에 따른 뉴스 기사 본문의 리스트로 정의된다.
뉴스 기사는 네이버의 증권 서비스(m.stock.naver.com)에서 자동으로 수집하였다.
이 서비스에는 각종 신문사의 뉴스 기사를 한데 모아서 종목 이름이나 코드로 검색하여 볼 수 있는 기능이 있다.
그러나 이 서비스에서는 공식적으로 REST API를 제공하지 않기 때문에 이에 대한 레퍼런스 문서가 공개되어 있지 않다.
따라서 자동화 스크립트를 작성하기 위해 먼저 해당 서비스의 사이트를 분석하였다.
그림 \ref{fig:naver_stock}은/는 크롬 웹브라우져 개발자 도구로 해당 사이트를 분석하는 모습이다.
\begin{figure}[h]
\includegraphics[width=0.9\textwidth]{naver_stock}
\centering
\caption{네이버 금융 서비스를 크롬 웹브라우져 개발자 도구로 분석하는 모습}
\label{fig:naver_stock}
\end{figure}
사이트 분석 결과 다음의 두 API end-point를 알 수 있었다.
\begin{itemize}
\item \texttt{GET /api/json/news/newsListJson.nhn?category=itemnewslist\&code=\&pageSize=\&page=}
\item \texttt{GET /api/html/item/itemNews.nhn?\&code=\&officeId=\&articleId=}
\end{itemize}
앞의 것은 종목 코드(\texttt{code})에 관련된 뉴스 기사들을 \texttt{pageSize}씩 나눴을 때 \texttt{page}번째에 해당하는 목록을 JSON 형식으로 돌려주는 API이다.
특정 회사의 종목 코드는 해당 서비스나 여러 증권사, 포털 사이트 등을 통해 쉽게 찾을 수 있다.
뒤의 것은 종목 코드(\texttt{code})와 신문사 아이디(\texttt{officeId}), 기사 아이디(\texttt{articleId})를 받아 해당 기사의 내용을 HTML 형식으로 돌려주는 API이다.
여기에 필요한 신문사 아이디와 기사 아이디는 목록 API 결과에 포함되어 있다.
자동화 스크립트는 Python 언어로 작성하였으며, 이를 통해 얻은 뉴스 기사 데이터는 인공 신경망 학습 코드를 간결하게 하기 위해 주가 데이터와 같이 MongoDB에 저장하였다.
Python의 \texttt{urllib} 라이브러리를 이용하여 REST 요청을 하고, \texttt{BeautifulSoup} 라이브러리를 이용하여 반환된 기사를 파싱하였다.
API에서 반환하는 기사는 제목, 내용, 광고 등이 섞여 있기 때문에 본문만 추출하고, 본문에도 내용과 상관없는 광고가 포함되어 있을 경우 제거해주었다.
실제로 앞서 선택한 6개의 종목에 대해 주가 데이터를 포괄할 수 있도록 현재(데이터 수집 당시 기준 5월 24일)부터 365일 이전의 기사까지 수집하였다.
수집한 기사의 개수는 표 \ref{tbl:number_of_articles}와/과 같았다.
\begin{table}[h]
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
종목 & 084990 & 214370 & 102940 & 095700 & 034830 & 046890 \\
\hline
개수 & 980 & 320 & 589 & 192 & 269 & 479 \\
\hline
\end{tabular}
\centering
\caption{종목별 수집한 기사의 개수}
\label{tbl:number_of_articles}
\end{table}

\section{예측 모델}

\begin{figure}[h]
\includegraphics[width=\textwidth]{model}
\centering
\caption{예측 모델의 구조}
\label{fig:model}
\end{figure}

본 연구의 예측 모델은 앞서 언급한 선행 연구의 것을 따르되 좀 더 간결하게 바꿔 보았다.
일단 뉴스 기사의 정렬에 사용한 시간 간격은 선행 연구 결과에서 가장 좋은 성능을 냈던 $[0, 20]$만을 사용하였다.
$[-20, 0]$은 과거 주가와 현재 주가의 상관 관계를 찾아주는 것이므로 예측이라는 목적과 어긋나기 때문에 제외하였다.
주가 데이터가 10분 단위로만 있기 때문에 뉴스 기사가 공개된 시각의 1분 단위를 버림하였다.
다음으로 점수화 과정에서 $\beta$-값과 index의 $\Delta price$를 통한 정규화는 제외하고 단순히 20분 후 주가에서 현재 주가를 나누고 1을 뺀 값을 사용했다.
즉, 몇 \%가 오르거나 내렸는지를 나타내는 값이다.
그에 따라서 레이블링의 기준이 되는 threshold $\rho$도 새로 정하였다.
우리나라 주식 시장의 매도 수수료가 $0.3\%$인 것에서 $\rho_{positive}=0.003$, $\rho_{negative}=-0.003$으로 설정하였다.
이렇게 하면 주가 변동이 $UP$이라고 할 때 해당 주식을 사고 20분 후에 팔면 실질적인 수익을 내게 된다는 의미가 있다.

본 연구의 예측 모델은 그림 \ref{fig:model}와/과 같이 전체 데이터를 시간 순으로 정렬하여
앞의 80\%는 학습(training)에 사용하고, 나머지 20\%를 사용하여 검증(testing) 하였다.
선행 연구와 다르게 본 연구에서 새로 도입한 자연어 처리와 인공 신경망에 대해서는 다음의 절에 차례대로 설명하였다.

\subsection{자연어 처리}

본 예측 모델은 인공 신경망 분류기를 사용하기 때문에 이 분류기의 입력이 되는 뉴스 기사를 하나의 feature 벡터로 표현해야 한다.
뉴스 기사의 본문이 주어졌을 때 feature 벡터를 추출하기 위해 형태소 분석 후에 TF-IDF를 계산하였다.
먼저, 모든 뉴스 기사에 대해 형태소 분석을 통해 명사만을 뽑아 내어 bag-of-words를 구성한다.
형태소 분석에는 Python 라이브러리인 \texttt{KoNLPy}에 있는 \texttt{MeCab} 분석기를 사용하였다.
다음으로, bag-of-words를 가지고 각 뉴스 기사에 대해 그 기사에 각 단어가 등장한 횟수를 센다.
즉, term frequency가 된다.
그리고 나서 term frequency를 각 단어가 포함된 뉴스 기사의 개수로 나누어주었다.
즉, term frequency $\times$ inverse term frequency (TF-IDF)가 된다.
TF-IDF를 사용한 이유는 대부분의 기사에 공통적으로 등장하는 주가와는 무의미한 단어들
(예를 들어 ``주가'', ``코스닥'' 등)을 걸러내는 효과적인 수단이기 때문이다.
각 종목별로 따로 처리 하였고, 그 결과 feature 벡터의 차원은 2,000에서 4,000 사이였으며 구체적인 값은 표 \ref{tbl:dimension}에 있다.
\begin{table}[h]
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
종목 & 084990 & 214370 & 102940 & 095700 & 034830 & 046890 \\
\hline
차원 & 3618 & 2606 & 3420 & 2490 & 2951 & 3139 \\
\hline
\end{tabular}
\centering
\caption{종목별 feature 벡터의 차원}
\label{tbl:dimension}
\end{table}

\subsection{인공 신경망}

주가 변동을 예측하는 분류기를 위한 인공 신경망은 Python 라이브러리인 \texttt{Keras}를 사용하여 구현하였다.
그 구조는 세 개의 층으로 이루어져 있으며 각 층은 다음과 같다.
\begin{enumerate}
\item feature 벡터를 입력으로 받아 4,096 차원의 출력을 내는 fully-connected layer
\item 이전 층의 출력을 입력으로 받아 2,048 차원의 출력을 내는 fully-connected layer
\item 이전 층의 출력을 입력으로 받아 3가지 레이블의 확률을 출력하는 softmax layer
\end{enumerate}
여기서 앞의 두 개의 층은 activation 함수로써 $tanh$ 함수를 사용하였고,
과다학습(overfitting)을 방지하기 위해 $0.5$의 확률로 dropout을 적용 하였다.
Stochastic gradient descent (SGD)로 모델을 학습시켰으며 batch learning을 총 100 epoch 수행하였다.
인공 신경망의 출력 벡터 요소 중 가장 큰 확률로 예측된 레이블을 최종 예측값으로 사용하였다.

\section{결과 분석}

먼저 학습이 정상적으로 이루어졌는지 확인하기 위해 epoch에 따른 loss와 accuracy를 보면,
\begin{figure}[h]
\includegraphics[width=0.49\textwidth]{epoch_loss}
\includegraphics[width=0.49\textwidth]{epoch_accuracy}
\centering
\caption{종목별 epoch에 따른 loss와 accuracy}
\label{fig:epoch_loss_accuracy}
\end{figure}
그림 \ref{fig:epoch_loss_accuracy}에서 보이는 것과 같이 loss가 줄어들고 accuracy가 증가하는 것을 확인할 수 있다.
100 epoch만에 loss 그래프만 보았을 때에는 수렴하였다고 보기 어려우나 accuracy가 수렴하는 시점으로 맞춘 것이기 때문에
hyperparameter인 epoch의 수 100은 정당한 선택이라고 할 수 있다.

종목별 테스트 결과 전체는 그림 \ref{fig:test_result}와 같았다.
\begin{figure}[h]
\includegraphics[width=\textwidth]{test_result}
\centering
\caption{종목별 테스트 결과 confusion matrix (왼쪽 위의 셀은 종목 코드, 오른쪽 아래의 셀은 accuracy, 가로축 레이블은 예측, 세로축 레이블은 정답)}
\label{fig:test_result}
\end{figure}

정확도(accuracy)에 대해, 단 하나의 레이블로만 예측하는 경우(Single 모델) 그리고 모든 레이블을 같은 확률로 예측하는 경우(Uniform 모델)와 본 모델을 비교해보았다.
\begin{figure}[h]
\includegraphics[width=0.8\textwidth]{accuracy_comparison}
\centering
\caption{종목별 테스트 결과 정확도 비교}
\label{fig:accuracy_comparison}
\end{figure}
Single 모델은 모든 레이블을 $DOWN$으로, $EXP$로, $UP$으로 예측하는 각각의 경우에 대한 정확도를 기하평균 낸 값이다.
Uniform 모델은 이상적으로 정확도가 언제나 $33.33\%$인 모델이다.
테스트 데이터의 레이블이 불균등하기 때문에 Single 모델의 성능은 Uniform 모델의 성능보다 낮을 수밖에 없다.
그러므로 본 모델과 Uniform 모델과의 비교만으로 충분할 것이다.
그림 \ref{fig:accuracy_comparison}을/를 보면, 본 모델이 Uniform 모델 보다 높은 정확도를 가지는 종목은 084990, 214370, 034830의 세 개였다.
반대로 Uniform 보다도 못한 정확도를 가지는 종목도 세 개로 같았다.
하지만 다행히도 본 모델의 정확도가 더 높은 세 종목의 정확도 차이 폭이 낮은 세 종목의 차이 폭 보다 상대적으로 크게 나타났다.
즉, 전체 종목에 대한 정확도는 $37.41\% (= 110/294)$로 Uniform 모델의 정확도 $33.33\%$ 보다 $4.08\%p$ 높았다.
선행 연구의 결과와 마찬가지로 예측력은 낮지만 효율적 시장 가설에 반하는 결과라고 할 수 있다.
뉴스 기사 데이터의 절대적인 양이 적고, 테스트한 종목의 수가 적기 때문에 통계적으로 큰 의미가 있다고 할 수는 없으나,
뉴스 기사 데이터의 수가 가장 많았던 종목인 084990에 대한 정확도가 $42.86\%$로 $33.33\%$보다 $9.52\%p$나 높게 나타난 것은 의미 있는 결과라고 할 수 있다.

\section{결론 및 제언}

선행 연구를 검증하는 목적으로 그와 비슷한 모델을 구현하여 KOSDAQ 시장에 상장한 6개의 종목에 대해 테스트를 해보았다.
테스트에 필요한 데이터는 지난 약 1년치의 주가와 뉴스 기사 데이터였다.
이베트스투자증권의 XingAPI를 이용한 Windows Form 응용 프로그램을 통해 주가 데이터를 얻었으며,
네이버 증권 사이트의 REST API를 분석하여 Python 스크립트를 통해 뉴스 기사 데이터를 얻었다.
이 중에 과거 80\%의 데이터는 학습 데이터로 활용하였고, 나머지 최근 20\%의 데이터는 테스트 데이터로 사용했다.
그 결과 세 가지 레이블을 동일한 확률로 예측하는 경우보다 $4.08\%p$ 높은 정확도를 갖는 것을 확인하였다.
하지만 뉴스 기사 데이터의 양이 적어서 그 결과가 통계적으로 큰 의미가 있다고 할 수 없는 한계가 있었다.
통계적으로 더 의미있는 결과를 얻기 위해서는 관련 뉴스 기사가 더 많은 종목에 대해, 그리고 더 많은 종목에 대해 같은 실험을 반복 해보면 좋을 것이다.

본 모델의 예측력이 높지 않은 원인을 꼽아보자면, 첫번째로 뉴스 기사 대부분의 내용이 주가가 어떻게 변동 했는지에 관한 정리를 하는 시황 뉴스였다.
시황 뉴스는 투자자들이 이미 주가의 변동을 봐서 알고 있는 정보이기 때문에 주가 변동 예측에 도움이 된다고 할 수 없다.
두번째로 선행 연구와 마찬가지로 시간 차이를 두고 여러 뉴스 기사가 같은 소식을 전달하고 있을 때 이들을 걸러내지 않은 채 모두 입력으로 사용하였다.
세번째로 선행 연구의 모델을 간소화 하였기 때문에 index의 변화량에 대한 보정과 변동성 $\beta$-값에 의한 정규화를 하지 않았다.
첫번째와 두번째 원인을 해결할 수 있는 방법으로는 topic modeling이 있다.
이를 통해 뉴스 기사를 비슷한 것끼리 묶고 단순히 시황을 전하는 뉴스나 같은 소식을 반복하는 뉴스를 걸러낼 수 있을 것이다.

본 연구를 더욱 발전시킨다면, 학습해놓은 모델을 가지고 실시간으로 공개되는 뉴스 기사를 넣어서,
$UP$으로 예측이 될 때 해당 종목을 사고 20분 후에 파는 모의 투자를 해볼 수 있을 것이다.
나아가, 각 종목에 대해 시간이 갈수록 이 모델을 점진적으로 학습시키는 강화 학습(Reinforcement Learning) 모델을 적용해볼 수 있겠다.
너무 오랜 과거의 정보는 최근의 주가 변동을 예측하는 데에 방해가 될 수 있으므로,
강화 학습 모델을 추적하여 학습한 기간이 1년, 2년씩 늘어갈 때 그 모델의 예측 정확도가 어떻게 변하는지 관찰해보고, 최적의 기간을 찾아보는 것도 흥미로울 것이다.
또한 여러 종목 중 예측 정확도가 높은 종목들은 어떤 특성을 갖는지 알아보고 그러한 종목들만을 특정 지을 수 있다면,
모의 투자를 통해 불로소득의 꿈을 달성할 수 있을 것이다.

\section*{참고문헌}

\begin{enumerate}[ {[}1{]} ]
\item Gidofalvi, Gyozo, and Charles Elkan. ``Using news articles to predict stock price movements.'' \textit{Department of Computer Science and Engineering, University of California, San Diego}. 2001.
\item Park, Eunjeong L., and Sungzoon Cho. ``KoNLPy: Korean natural language processing in Python.'' \textit{Proceedings of the 26th Annual Conference on Human and Cognitive Language Technology}. 2014.
\item 이베스트투자증권. ``XingAPI COM 개발 가이드'' \texttt{http://etrade.co.kr/apiguide/guide.jsp?cno=200}.
\item 조대표. ``파이썬을 이용한 시스템 트레이딩 (기초편)'' \texttt{https://wikidocs.net/book/110}.
\end{enumerate}

\section*{부록}

소스 코드: \url{https://github.com/sim0629/nstock}

\end{document}
